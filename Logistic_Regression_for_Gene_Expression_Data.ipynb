{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Logistic Regression for Gene Expression Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HINLQYXQOmD6"
      },
      "source": [
        "To predict biological characteristics (\"phenotypes\") from gene expression data.  \n",
        "\n",
        "In this data, mice were characterized by three properties:\n",
        "* Whether they had down's syndrome (trisomy) or not\n",
        "* Whether they were stimulated to learn or not\n",
        "* Whether they had a drug memantine or a saline control solution.\n",
        "\n",
        "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  To predict genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHIjd6B1OmD7"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJqkpI64OmD8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nMcj1w1OmD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "03eedc0d-b1f6-45c7-ac27-e3e9a99d482c"
      },
      "source": [
        "df = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\", \n",
        "                   index_col = 0) \n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DYRK1A_N</th>\n",
              "      <th>ITSN1_N</th>\n",
              "      <th>BDNF_N</th>\n",
              "      <th>NR1_N</th>\n",
              "      <th>NR2A_N</th>\n",
              "      <th>pAKT_N</th>\n",
              "      <th>pBRAF_N</th>\n",
              "      <th>pCAMKII_N</th>\n",
              "      <th>pCREB_N</th>\n",
              "      <th>pELK_N</th>\n",
              "      <th>pERK_N</th>\n",
              "      <th>pJNK_N</th>\n",
              "      <th>PKCA_N</th>\n",
              "      <th>pMEK_N</th>\n",
              "      <th>pNR1_N</th>\n",
              "      <th>pNR2A_N</th>\n",
              "      <th>pNR2B_N</th>\n",
              "      <th>pPKCAB_N</th>\n",
              "      <th>pRSK_N</th>\n",
              "      <th>AKT_N</th>\n",
              "      <th>BRAF_N</th>\n",
              "      <th>CAMKII_N</th>\n",
              "      <th>CREB_N</th>\n",
              "      <th>ELK_N</th>\n",
              "      <th>ERK_N</th>\n",
              "      <th>GSK3B_N</th>\n",
              "      <th>JNK_N</th>\n",
              "      <th>MEK_N</th>\n",
              "      <th>TRKA_N</th>\n",
              "      <th>RSK_N</th>\n",
              "      <th>APP_N</th>\n",
              "      <th>Bcatenin_N</th>\n",
              "      <th>SOD1_N</th>\n",
              "      <th>MTOR_N</th>\n",
              "      <th>P38_N</th>\n",
              "      <th>pMTOR_N</th>\n",
              "      <th>DSCR1_N</th>\n",
              "      <th>AMPKA_N</th>\n",
              "      <th>NR2B_N</th>\n",
              "      <th>pNUMB_N</th>\n",
              "      <th>...</th>\n",
              "      <th>TIAM1_N</th>\n",
              "      <th>pP70S6_N</th>\n",
              "      <th>NUMB_N</th>\n",
              "      <th>P70S6_N</th>\n",
              "      <th>pGSK3B_N</th>\n",
              "      <th>pPKCG_N</th>\n",
              "      <th>CDK5_N</th>\n",
              "      <th>S6_N</th>\n",
              "      <th>ADARB1_N</th>\n",
              "      <th>AcetylH3K9_N</th>\n",
              "      <th>RRP1_N</th>\n",
              "      <th>BAX_N</th>\n",
              "      <th>ARC_N</th>\n",
              "      <th>ERBB4_N</th>\n",
              "      <th>nNOS_N</th>\n",
              "      <th>Tau_N</th>\n",
              "      <th>GFAP_N</th>\n",
              "      <th>GluR3_N</th>\n",
              "      <th>GluR4_N</th>\n",
              "      <th>IL1B_N</th>\n",
              "      <th>P3525_N</th>\n",
              "      <th>pCASP9_N</th>\n",
              "      <th>PSD95_N</th>\n",
              "      <th>SNCA_N</th>\n",
              "      <th>Ubiquitin_N</th>\n",
              "      <th>pGSK3B_Tyr216_N</th>\n",
              "      <th>SHH_N</th>\n",
              "      <th>BAD_N</th>\n",
              "      <th>BCL2_N</th>\n",
              "      <th>pS6_N</th>\n",
              "      <th>pCFOS_N</th>\n",
              "      <th>SYP_N</th>\n",
              "      <th>H3AcK18_N</th>\n",
              "      <th>EGR1_N</th>\n",
              "      <th>H3MeK4_N</th>\n",
              "      <th>CaNA_N</th>\n",
              "      <th>Genotype</th>\n",
              "      <th>Treatment</th>\n",
              "      <th>Behavior</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MouseID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309_1</th>\n",
              "      <td>0.503644</td>\n",
              "      <td>0.747193</td>\n",
              "      <td>0.430175</td>\n",
              "      <td>2.816329</td>\n",
              "      <td>5.990152</td>\n",
              "      <td>0.218830</td>\n",
              "      <td>0.177565</td>\n",
              "      <td>2.373744</td>\n",
              "      <td>0.232224</td>\n",
              "      <td>1.750936</td>\n",
              "      <td>0.687906</td>\n",
              "      <td>0.306382</td>\n",
              "      <td>0.402698</td>\n",
              "      <td>0.296927</td>\n",
              "      <td>1.022060</td>\n",
              "      <td>0.605673</td>\n",
              "      <td>1.877684</td>\n",
              "      <td>2.308745</td>\n",
              "      <td>0.441599</td>\n",
              "      <td>0.859366</td>\n",
              "      <td>0.416289</td>\n",
              "      <td>0.369608</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>1.866358</td>\n",
              "      <td>3.685247</td>\n",
              "      <td>1.537227</td>\n",
              "      <td>0.264526</td>\n",
              "      <td>0.319677</td>\n",
              "      <td>0.813866</td>\n",
              "      <td>0.165846</td>\n",
              "      <td>0.453910</td>\n",
              "      <td>3.037621</td>\n",
              "      <td>0.369510</td>\n",
              "      <td>0.458539</td>\n",
              "      <td>0.335336</td>\n",
              "      <td>0.825192</td>\n",
              "      <td>0.576916</td>\n",
              "      <td>0.448099</td>\n",
              "      <td>0.586271</td>\n",
              "      <td>0.394721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482864</td>\n",
              "      <td>0.294170</td>\n",
              "      <td>0.182150</td>\n",
              "      <td>0.842725</td>\n",
              "      <td>0.192608</td>\n",
              "      <td>1.443091</td>\n",
              "      <td>0.294700</td>\n",
              "      <td>0.354605</td>\n",
              "      <td>1.339070</td>\n",
              "      <td>0.170119</td>\n",
              "      <td>0.159102</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>0.176668</td>\n",
              "      <td>0.125190</td>\n",
              "      <td>0.115291</td>\n",
              "      <td>0.228043</td>\n",
              "      <td>0.142756</td>\n",
              "      <td>0.430957</td>\n",
              "      <td>0.247538</td>\n",
              "      <td>1.603310</td>\n",
              "      <td>2.014875</td>\n",
              "      <td>0.108234</td>\n",
              "      <td>1.044979</td>\n",
              "      <td>0.831557</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.122652</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.108336</td>\n",
              "      <td>0.427099</td>\n",
              "      <td>0.114783</td>\n",
              "      <td>0.131790</td>\n",
              "      <td>0.128186</td>\n",
              "      <td>1.675652</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_2</th>\n",
              "      <td>0.514617</td>\n",
              "      <td>0.689064</td>\n",
              "      <td>0.411770</td>\n",
              "      <td>2.789514</td>\n",
              "      <td>5.685038</td>\n",
              "      <td>0.211636</td>\n",
              "      <td>0.172817</td>\n",
              "      <td>2.292150</td>\n",
              "      <td>0.226972</td>\n",
              "      <td>1.596377</td>\n",
              "      <td>0.695006</td>\n",
              "      <td>0.299051</td>\n",
              "      <td>0.385987</td>\n",
              "      <td>0.281319</td>\n",
              "      <td>0.956676</td>\n",
              "      <td>0.587559</td>\n",
              "      <td>1.725774</td>\n",
              "      <td>2.043037</td>\n",
              "      <td>0.445222</td>\n",
              "      <td>0.834659</td>\n",
              "      <td>0.400364</td>\n",
              "      <td>0.356178</td>\n",
              "      <td>0.173680</td>\n",
              "      <td>1.761047</td>\n",
              "      <td>3.485287</td>\n",
              "      <td>1.509249</td>\n",
              "      <td>0.255727</td>\n",
              "      <td>0.304419</td>\n",
              "      <td>0.780504</td>\n",
              "      <td>0.157194</td>\n",
              "      <td>0.430940</td>\n",
              "      <td>2.921882</td>\n",
              "      <td>0.342279</td>\n",
              "      <td>0.423560</td>\n",
              "      <td>0.324835</td>\n",
              "      <td>0.761718</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.420876</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.368255</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454519</td>\n",
              "      <td>0.276431</td>\n",
              "      <td>0.182086</td>\n",
              "      <td>0.847615</td>\n",
              "      <td>0.194815</td>\n",
              "      <td>1.439460</td>\n",
              "      <td>0.294060</td>\n",
              "      <td>0.354548</td>\n",
              "      <td>1.306323</td>\n",
              "      <td>0.171427</td>\n",
              "      <td>0.158129</td>\n",
              "      <td>0.184570</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.150471</td>\n",
              "      <td>0.178309</td>\n",
              "      <td>0.134275</td>\n",
              "      <td>0.118235</td>\n",
              "      <td>0.238073</td>\n",
              "      <td>0.142037</td>\n",
              "      <td>0.457156</td>\n",
              "      <td>0.257632</td>\n",
              "      <td>1.671738</td>\n",
              "      <td>2.004605</td>\n",
              "      <td>0.109749</td>\n",
              "      <td>1.009883</td>\n",
              "      <td>0.849270</td>\n",
              "      <td>0.200404</td>\n",
              "      <td>0.116682</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.104315</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.111974</td>\n",
              "      <td>0.135103</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>1.743610</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_3</th>\n",
              "      <td>0.509183</td>\n",
              "      <td>0.730247</td>\n",
              "      <td>0.418309</td>\n",
              "      <td>2.687201</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>0.209011</td>\n",
              "      <td>0.175722</td>\n",
              "      <td>2.283337</td>\n",
              "      <td>0.230247</td>\n",
              "      <td>1.561316</td>\n",
              "      <td>0.677348</td>\n",
              "      <td>0.291276</td>\n",
              "      <td>0.381002</td>\n",
              "      <td>0.281710</td>\n",
              "      <td>1.003635</td>\n",
              "      <td>0.602449</td>\n",
              "      <td>1.731873</td>\n",
              "      <td>2.017984</td>\n",
              "      <td>0.467668</td>\n",
              "      <td>0.814329</td>\n",
              "      <td>0.399847</td>\n",
              "      <td>0.368089</td>\n",
              "      <td>0.173905</td>\n",
              "      <td>1.765544</td>\n",
              "      <td>3.571456</td>\n",
              "      <td>1.501244</td>\n",
              "      <td>0.259614</td>\n",
              "      <td>0.311747</td>\n",
              "      <td>0.785154</td>\n",
              "      <td>0.160895</td>\n",
              "      <td>0.423187</td>\n",
              "      <td>2.944136</td>\n",
              "      <td>0.343696</td>\n",
              "      <td>0.425005</td>\n",
              "      <td>0.324852</td>\n",
              "      <td>0.757031</td>\n",
              "      <td>0.543620</td>\n",
              "      <td>0.404630</td>\n",
              "      <td>0.552994</td>\n",
              "      <td>0.363880</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447197</td>\n",
              "      <td>0.256648</td>\n",
              "      <td>0.184388</td>\n",
              "      <td>0.856166</td>\n",
              "      <td>0.200737</td>\n",
              "      <td>1.524364</td>\n",
              "      <td>0.301881</td>\n",
              "      <td>0.386087</td>\n",
              "      <td>1.279600</td>\n",
              "      <td>0.185456</td>\n",
              "      <td>0.148696</td>\n",
              "      <td>0.190532</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.145330</td>\n",
              "      <td>0.176213</td>\n",
              "      <td>0.132560</td>\n",
              "      <td>0.117760</td>\n",
              "      <td>0.244817</td>\n",
              "      <td>0.142445</td>\n",
              "      <td>0.510472</td>\n",
              "      <td>0.255343</td>\n",
              "      <td>1.663550</td>\n",
              "      <td>2.016831</td>\n",
              "      <td>0.108196</td>\n",
              "      <td>0.996848</td>\n",
              "      <td>0.846709</td>\n",
              "      <td>0.193685</td>\n",
              "      <td>0.118508</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.106219</td>\n",
              "      <td>0.435777</td>\n",
              "      <td>0.111883</td>\n",
              "      <td>0.133362</td>\n",
              "      <td>0.127431</td>\n",
              "      <td>1.926427</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_4</th>\n",
              "      <td>0.442107</td>\n",
              "      <td>0.617076</td>\n",
              "      <td>0.358626</td>\n",
              "      <td>2.466947</td>\n",
              "      <td>4.979503</td>\n",
              "      <td>0.222886</td>\n",
              "      <td>0.176463</td>\n",
              "      <td>2.152301</td>\n",
              "      <td>0.207004</td>\n",
              "      <td>1.595086</td>\n",
              "      <td>0.583277</td>\n",
              "      <td>0.296729</td>\n",
              "      <td>0.377087</td>\n",
              "      <td>0.313832</td>\n",
              "      <td>0.875390</td>\n",
              "      <td>0.520293</td>\n",
              "      <td>1.566852</td>\n",
              "      <td>2.132754</td>\n",
              "      <td>0.477671</td>\n",
              "      <td>0.727705</td>\n",
              "      <td>0.385639</td>\n",
              "      <td>0.362970</td>\n",
              "      <td>0.179449</td>\n",
              "      <td>1.286277</td>\n",
              "      <td>2.970137</td>\n",
              "      <td>1.419710</td>\n",
              "      <td>0.259536</td>\n",
              "      <td>0.279218</td>\n",
              "      <td>0.734492</td>\n",
              "      <td>0.162210</td>\n",
              "      <td>0.410615</td>\n",
              "      <td>2.500204</td>\n",
              "      <td>0.344509</td>\n",
              "      <td>0.429211</td>\n",
              "      <td>0.330121</td>\n",
              "      <td>0.746980</td>\n",
              "      <td>0.546763</td>\n",
              "      <td>0.386860</td>\n",
              "      <td>0.547849</td>\n",
              "      <td>0.366771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.442650</td>\n",
              "      <td>0.398534</td>\n",
              "      <td>0.161768</td>\n",
              "      <td>0.760234</td>\n",
              "      <td>0.184169</td>\n",
              "      <td>1.612382</td>\n",
              "      <td>0.296382</td>\n",
              "      <td>0.290680</td>\n",
              "      <td>1.198765</td>\n",
              "      <td>0.159799</td>\n",
              "      <td>0.166112</td>\n",
              "      <td>0.185323</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.140656</td>\n",
              "      <td>0.163804</td>\n",
              "      <td>0.123210</td>\n",
              "      <td>0.117439</td>\n",
              "      <td>0.234947</td>\n",
              "      <td>0.145068</td>\n",
              "      <td>0.430996</td>\n",
              "      <td>0.251103</td>\n",
              "      <td>1.484624</td>\n",
              "      <td>1.957233</td>\n",
              "      <td>0.119883</td>\n",
              "      <td>0.990225</td>\n",
              "      <td>0.833277</td>\n",
              "      <td>0.192112</td>\n",
              "      <td>0.132781</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.111262</td>\n",
              "      <td>0.391691</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.147444</td>\n",
              "      <td>0.146901</td>\n",
              "      <td>1.700563</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_5</th>\n",
              "      <td>0.434940</td>\n",
              "      <td>0.617430</td>\n",
              "      <td>0.358802</td>\n",
              "      <td>2.365785</td>\n",
              "      <td>4.718679</td>\n",
              "      <td>0.213106</td>\n",
              "      <td>0.173627</td>\n",
              "      <td>2.134014</td>\n",
              "      <td>0.192158</td>\n",
              "      <td>1.504230</td>\n",
              "      <td>0.550960</td>\n",
              "      <td>0.286961</td>\n",
              "      <td>0.363502</td>\n",
              "      <td>0.277964</td>\n",
              "      <td>0.864912</td>\n",
              "      <td>0.507990</td>\n",
              "      <td>1.480059</td>\n",
              "      <td>2.013697</td>\n",
              "      <td>0.483416</td>\n",
              "      <td>0.687794</td>\n",
              "      <td>0.367531</td>\n",
              "      <td>0.355311</td>\n",
              "      <td>0.174836</td>\n",
              "      <td>1.324695</td>\n",
              "      <td>2.896334</td>\n",
              "      <td>1.359876</td>\n",
              "      <td>0.250705</td>\n",
              "      <td>0.273667</td>\n",
              "      <td>0.702699</td>\n",
              "      <td>0.154827</td>\n",
              "      <td>0.398550</td>\n",
              "      <td>2.456560</td>\n",
              "      <td>0.329126</td>\n",
              "      <td>0.408755</td>\n",
              "      <td>0.313415</td>\n",
              "      <td>0.691956</td>\n",
              "      <td>0.536860</td>\n",
              "      <td>0.360816</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>0.351551</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419095</td>\n",
              "      <td>0.393447</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.768113</td>\n",
              "      <td>0.185718</td>\n",
              "      <td>1.645807</td>\n",
              "      <td>0.296829</td>\n",
              "      <td>0.309345</td>\n",
              "      <td>1.206995</td>\n",
              "      <td>0.164650</td>\n",
              "      <td>0.160687</td>\n",
              "      <td>0.188221</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.141983</td>\n",
              "      <td>0.167710</td>\n",
              "      <td>0.136838</td>\n",
              "      <td>0.116048</td>\n",
              "      <td>0.255528</td>\n",
              "      <td>0.140871</td>\n",
              "      <td>0.481227</td>\n",
              "      <td>0.251773</td>\n",
              "      <td>1.534835</td>\n",
              "      <td>2.009109</td>\n",
              "      <td>0.119524</td>\n",
              "      <td>0.997775</td>\n",
              "      <td>0.878668</td>\n",
              "      <td>0.205604</td>\n",
              "      <td>0.129954</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.434154</td>\n",
              "      <td>0.118481</td>\n",
              "      <td>0.140314</td>\n",
              "      <td>0.148380</td>\n",
              "      <td>1.839730</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         DYRK1A_N   ITSN1_N    BDNF_N  ...  Treatment  Behavior   class\n",
              "MouseID                                ...                             \n",
              "309_1    0.503644  0.747193  0.430175  ...  Memantine       C/S  c-CS-m\n",
              "309_2    0.514617  0.689064  0.411770  ...  Memantine       C/S  c-CS-m\n",
              "309_3    0.509183  0.730247  0.418309  ...  Memantine       C/S  c-CS-m\n",
              "309_4    0.442107  0.617076  0.358626  ...  Memantine       C/S  c-CS-m\n",
              "309_5    0.434940  0.617430  0.358802  ...  Memantine       C/S  c-CS-m\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VzkuYjhOmEC"
      },
      "source": [
        "df1 = df.fillna(df.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP9WrSSSOmEE"
      },
      "source": [
        "## Binary Classification for Down's Syndrome\n",
        "\n",
        "Predicting the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX6gA0ncOmEE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ea09d8c-35c5-45ff-f486-621ea5ef7c8b"
      },
      "source": [
        "y = np.unique(df1['Genotype'] , return_inverse= True)[1]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbF72sSCOmEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c5ef2e25-0291-4a9b-d8e1-7aa191347f0e"
      },
      "source": [
        "xnames = df1.columns.values[:-4]\n",
        "\n",
        "X = np.array(df1[xnames])\n",
        "\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50364388, 0.74719322, 0.4301753 , ..., 0.13179003, 0.1281856 ,\n",
              "        1.67565235],\n",
              "       [0.51461708, 0.68906355, 0.41177034, ..., 0.13510297, 0.1311187 ,\n",
              "        1.74360965],\n",
              "       [0.50918309, 0.7302468 , 0.41830878, ..., 0.13336183, 0.12743108,\n",
              "        1.92642659],\n",
              "       ...,\n",
              "       [0.22869955, 0.39517937, 0.23411809, ..., 0.22919311, 0.35521305,\n",
              "        1.43082502],\n",
              "       [0.22124241, 0.41289438, 0.24397413, ..., 0.25131651, 0.36535319,\n",
              "        1.40403123],\n",
              "       [0.30262572, 0.46105919, 0.25656431, ..., 0.25299481, 0.36527803,\n",
              "        1.37099946]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYxstTNMOmEK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxSA7sC4OmEN"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create scaler object\n",
        "scaler = StandardScaler()\n",
        "# Fit with training data\n",
        "scaler.fit(Xtr)\n",
        "# Transform train and test data\n",
        "Xtr1 = scaler.transform(Xtr)\n",
        "Xts1 = scaler.transform(Xts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JseR5MMXOmEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b07865f2-74fc-4bf7-9a09-9c7dd140648c"
      },
      "source": [
        "logreg = linear_model.LogisticRegression(C=1e5, solver = 'liblinear')\n",
        "logreg.fit(Xtr1, ytr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg5LrHHROmES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3407a17-431e-49d6-c4d3-00206f6e3a81"
      },
      "source": [
        "yhat = logreg.predict(Xts1)\n",
        "acc = np.mean(yhat == yts)\n",
        "print(\"Accuracy on test data = %f\" % acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data = 0.947531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15O96kSdOmEU"
      },
      "source": [
        "## Interpreting the weight vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zdook9_OmEV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8c628039-11da-4f2e-b4fc-62f60d1dcd47"
      },
      "source": [
        "W = logreg.coef_[0]\n",
        "plt.stem(W, use_line_collection=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdzvbjQCOmEX"
      },
      "source": [
        "Names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZtlPTdbOmEX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9841f92-ae0e-4062-8272-a08eedb84b8c"
      },
      "source": [
        "xnames[W.argsort()[-2:]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['APP_N', 'ITSN1_N'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRIPYJfeOmEa"
      },
      "source": [
        "## Cross Validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvgjGMU9OmEa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b7a7d913-8876-42a0-fc52-5a0b9568f874"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "acc = np.zeros(nfold)\n",
        "prec = np.zeros(nfold)\n",
        "rec = np.zeros(nfold)\n",
        "f1 = np.zeros(nfold)\n",
        "\n",
        "for i, I in enumerate(kf.split(X)):\n",
        "    \n",
        "    # Get training and test data\n",
        "    train, test = I\n",
        "    Xtr = X[train,:]\n",
        "    ytr = y[train]\n",
        "    Xts = X[test,:]\n",
        "    yts = y[test]\n",
        "    \n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    Xtr1 = scaler.fit_transform(Xtr)\n",
        "    Xts1 = scaler.transform(Xts)    \n",
        "    \n",
        "    # Fit a model    \n",
        "    logreg.fit(Xtr1, ytr)\n",
        "    \n",
        "    # Predict on test samples and measure accuracy\n",
        "    yhat = logreg.predict(Xts1)\n",
        "    acc[i] = np.mean(yhat == yts)\n",
        "    \n",
        "    # Measure other performance metrics\n",
        "    prec[i],rec[i],f1[i],_  = precision_recall_fscore_support(yts,yhat,average='binary') \n",
        "    \n",
        "\n",
        "# Take average values of the metrics\n",
        "precm = np.mean(prec)\n",
        "recm = np.mean(rec)\n",
        "f1m = np.mean(f1)\n",
        "accm= np.mean(acc)\n",
        "\n",
        "print('Precision = %f' %precm)\n",
        "print('Recall = %f' %recm)\n",
        "print('f1 = %f' %f1m)\n",
        "print('Accuracy = %f' %accm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.946117\n",
            "Recall = 0.968677\n",
            "f1 = 0.956682\n",
            "Accuracy = 0.959259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v40XBT9IOmEc"
      },
      "source": [
        "## Multi-Class Classification\n",
        "\n",
        "Now using the response variable in `df1['class']`.  This has 8 possible classes.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xzZ6upwOmEd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17637c02-f2a3-4e9f-ebdb-566f62f753d8"
      },
      "source": [
        "y = np.unique(df1['class'] , return_inverse= True)[1]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 7, 7, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcH_p557OmEg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0031c850-eca2-4611-fa10-318039cba7e1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# TODO\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "acc = np.zeros(nfold)\n",
        "prec = np.zeros(nfold)\n",
        "rec = np.zeros(nfold)\n",
        "f1 = np.zeros(nfold)\n",
        "\n",
        "C = np.zeros((8, 8))\n",
        "\n",
        "for i, I in enumerate(kf.split(X)):\n",
        "    \n",
        "    # Get training and test data\n",
        "    train, test = I\n",
        "    Xtr = X[train,:]\n",
        "    ytr = y[train]\n",
        "    Xts = X[test,:]\n",
        "    yts = y[test]\n",
        "    \n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    Xtr1 = scaler.fit_transform(Xtr)\n",
        "    Xts1 = scaler.transform(Xts)    \n",
        "    \n",
        "    # Fit a model    \n",
        "    logreg.fit(Xtr1, ytr)\n",
        "    \n",
        "    # Predict on test samples and measure accuracy\n",
        "    yhat = logreg.predict(Xts1)\n",
        "    acc[i] = np.mean(yhat == yts)\n",
        "    \n",
        "    # Confusion metrics\n",
        "    C = C + confusion_matrix(yts,yhat)\n",
        "    \n",
        "\n",
        "# Take average values of the metrics\n",
        "accm= np.mean(acc)\n",
        "\n",
        "# normalize the rows of the confusion matrix so that they sum to one\n",
        "C = C / C.sum(axis=1)\n",
        "\n",
        "print('Accuracy = %f' %accm)\n",
        "\n",
        "print(np.array_str(C, precision=4, suppress_small=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.987963\n",
            "[[0.98   0.0074 0.     0.     0.     0.0095 0.     0.0074]\n",
            " [0.02   0.9704 0.     0.     0.0074 0.     0.     0.    ]\n",
            " [0.     0.0074 0.9867 0.     0.0074 0.     0.     0.    ]\n",
            " [0.0133 0.     0.     0.9852 0.     0.     0.     0.    ]\n",
            " [0.     0.0074 0.     0.     0.9926 0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.0074 0.     0.     0.9926 0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfv1gw3qOmEj"
      },
      "source": [
        "Re-running the logistic regression on the entire training data and get the weight coefficients.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7btNQcQOmEj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "089754e8-a51e-49b1-acde-5b41e8e89ef2"
      },
      "source": [
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X1 = scaler.fit_transform(X)\n",
        "\n",
        "# Fit a model    \n",
        "logreg.fit(X, y)\n",
        "W = logreg.coef_\n",
        "W.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 77)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p65sQOv7u1Mm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "fb7bcdd9-4d67-4014-a945-fef16b181415"
      },
      "source": [
        "plt.stem(W[0,:], use_line_collection=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1Mmn0fUiOmEl"
      },
      "source": [
        "## L1-Regularization\n",
        "\n",
        "In most genetic problems, only a limited number of the tested genes are likely influence any particular attribute.  Hence, the weight coefficients in the logistic regression model should be sparse.  Genetic analysis commonly imposes sparsity by adding an l1-penalty term. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq4c5fKoOmEl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ae1f97e3-a065-4679-c876-14ce3859b8de"
      },
      "source": [
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "C = np.logspace(-1,2,20)\n",
        "acc = np.zeros((20,nfold))\n",
        "\n",
        "for row, c in enumerate(C):\n",
        "\n",
        "  for col, I in enumerate(kf.split(X)):\n",
        "\n",
        "    # Get training and test data\n",
        "    train, test = I\n",
        "    Xtr = X[train,:]\n",
        "    ytr = y[train]\n",
        "    Xts = X[test,:]\n",
        "    yts = y[test]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    Xtr1 = scaler.fit_transform(Xtr)\n",
        "    Xts1 = scaler.transform(Xts)    \n",
        "\n",
        "    logreg2 = linear_model.LogisticRegression(penalty = 'l1', C = c, solver = 'liblinear')\n",
        "\n",
        "    # Fit a model    \n",
        "    logreg2.fit(Xtr1, ytr)\n",
        "\n",
        "    # Predict on test samples and measure accuracy\n",
        "    yhat = logreg2.predict(Xts1)\n",
        "    acc[row, col] = np.mean(yhat == yts)\n",
        "\n",
        "# Take average of accuracy over each row\n",
        "accm = np.mean(acc, axis=1)\n",
        "\n",
        "print(accm)\n",
        "print(\"-------\")\n",
        "print(\"Range of C between -1 to 2 provides the best results from all the values I tried\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.94537037 0.96018519 0.97407407 0.98055556 0.98425926 0.99074074\n",
            " 0.98888889 0.98796296 0.99074074 0.99166667 0.99166667 0.99166667\n",
            " 0.99259259 0.99074074 0.98981481 0.99166667 0.99351852 0.99166667\n",
            " 0.99259259 0.98888889]\n",
            "-------\n",
            "Range of C between -1 to 2 provides the best results from all the values I tried\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPqwmKTG_je3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e40c426a-90ac-4543-d01d-5a3e6823e446"
      },
      "source": [
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X1 = scaler.fit_transform(X)\n",
        "\n",
        "# Fit a model    \n",
        "logreg2 = linear_model.LogisticRegression(penalty = 'l1', C = c, solver = 'liblinear')\n",
        "logreg2.fit(X1, y)\n",
        "W = logreg.coef_\n",
        "\n",
        "plt.stem(W[0,:], use_line_collection=True)\n",
        "\n",
        "print(\"As seen, weight coeff for less significant features have been reduced and are closer to zero\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "As seen, weight coeff for less significant features have been reduced and are closer to zero\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-7oJ8fX-qYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9c2ea15e-fe58-4178-c5e5-974fca8016f9"
      },
      "source": [
        "# Average of all the accuracies \n",
        "avg_acc = np.mean(accm)\n",
        "print(avg_acc)\n",
        "print(\"-------\")\n",
        "print(\"Accuracy achieved with regularization is similar to that achieved without L1.\") \n",
        "print(\"But this is because I have used Standard Scaler earlier, had that not been used, the result would be significantly greater\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.985462962962963\n",
            "-------\n",
            "Accuracy achieved with regularization is similar to that achieved without L1.\n",
            "But this is because I have used Standard Scaler earlier, had that not been used, the result would be significantly greater\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNNC-f04D1fO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}